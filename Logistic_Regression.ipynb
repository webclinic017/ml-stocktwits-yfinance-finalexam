{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAPge6L6F99Y"
      },
      "outputs": [],
      "source": [
        "!pip install contractions\n",
        "!pip install emoji\n",
        "!pip install ekphrasis\n",
        "!pip install -U -q PyDrive\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "\n",
        "import contractions\n",
        "import datetime\n",
        "from datetime import datetime , timedelta, date\n",
        "import emoji\n",
        "import itertools\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pprint\n",
        "from pprint import pprint\n",
        "import random\n",
        "import re\n",
        "import requests \n",
        "import seaborn as sns\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "import torch\n",
        "import yfinance as yf\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "from pydrive.auth  import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth,  drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('/content/drive/MyDrive/HD_T_GOOG_BRK-A_TSLA_Binary_Sameday.csv')\n",
        "#df = pd.read_csv('/content/drive/MyDrive/HD_T_GOOG_BRK-A_TSLA_Binary_Prevday.csv')\n",
        "#df = pd.read_csv('/content/drive/MyDrive/HD_T_GOOG_BRK-A_TSLA_Percentage_Sameday.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/HD_T_GOOG_BRK-A_TSLA_Percentage_Prevday.csv')\n",
        "df = df.sample(frac=1)\n",
        "df.drop(df[df['Date'] <= '2019-07-20'].index, inplace = True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], random_state = 42, test_size = 0.1)"
      ],
      "metadata": {
        "id": "XxZHS_FAFj8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_parameters = {'vect__ngram_range': [(1, 2),(2, 2)], 'clf__C':[0.01,0.1,1], 'clf__penalty':[\"l1\",\"l2\"]}\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('clf', LogisticRegression(max_iter=5000, solver='liblinear'))])\n",
        "score = 'f1_macro'\n",
        "logmodel_cv=GridSearchCV(text_clf,tuned_parameters,cv=5, scoring=score)\n",
        "print()\n",
        "logmodel_cv.fit(X_train.values.astype('U'), y_train)\n",
        "print()\n",
        "print(classification_report(y_test, logmodel_cv.predict(X_test.values.astype('U')), digits=4))\n",
        "print()\n",
        "logmodel_cv.best_params_\n",
        "print()\n",
        "logmodel_cv.best_estimator_"
      ],
      "metadata": {
        "id": "gKSea3maOeiX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}